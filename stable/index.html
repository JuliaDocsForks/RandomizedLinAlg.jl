<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · RandomizedLinAlg.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>RandomizedLinAlg.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href="index.html">Home</a><ul class="internal"><li><a class="toctext" href="#Condition-number-estimate-1">Condition number estimate</a></li><li><a class="toctext" href="#Extremal-eigenvalue-estimates-1">Extremal eigenvalue estimates</a></li><li><a class="toctext" href="#Norm-estimate-1">Norm estimate</a></li><li><a class="toctext" href="#Interpolative-Decomposition-1">Interpolative Decomposition</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href="index.html">Home</a></li></ul><a class="edit-page" href="https://github.com/haampie/RandomizedLinAlg.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Randomized-1" href="#Randomized-1">Randomized Linear Algebra</a></h1><p>RandomizedLinAlg.jl is a Julia package that provides some randomized algorithms for numerical linear algebra as advocated in <a href="#footnote-Halko2011">[Halko2011]</a>.</p><pre><code class="language-none">reigen
rsvd
rsvd_fnkz</code></pre><h2><a class="nav-anchor" id="Condition-number-estimate-1" href="#Condition-number-estimate-1">Condition number estimate</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="RandomizedLinAlg.rcond" href="#RandomizedLinAlg.rcond"><code>RandomizedLinAlg.rcond</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">rcond(A, iters=1)</code></pre><p>Estimate matrix condition number randomly.</p><p><strong>Arguments</strong></p><ul><li><code>A</code>: matrix whose condition number to estimate. Must be square and</li></ul><p>support premultiply (<code>A*⋅</code>) and solve (<code>A\⋅</code>).</p><ul><li><code>iters::Int = 1</code>: number of power iterations to run.</li></ul><p><strong>Keywords</strong></p><ul><li><code>p::Real = 0.05</code>: probability that estimate fails to hold as an upper bound.</li></ul><p><strong>Output</strong></p><p>Interval <code>(x, y)</code> which contains <code>κ(A)</code> with probability <code>1 - p</code>.</p><p><strong>Implementation note</strong></p><p><a href="#footnote-Dixon1983">[Dixon1983]</a> originally describes this as a computation that can be done by computing the necessary number of power iterations given p and the desired accuracy parameter <code>θ=y/x</code>. However, these bounds were only derived under the assumptions of exact arithmetic. Empirically, <code>iters≥4</code> has been seen to result in incorrect results in that the computed interval does not contain the true condition number. This implemention therefore makes <code>iters</code> an explicitly user-controllable parameter from which to infer the accuracy parameter and hence the interval containing <code>κ(A)</code>. ```</p></div></div><a class="source-link" target="_blank" href="https://github.com/haampie/RandomizedLinAlg.jl/blob/491c91d7b5a15a7addf8f47afacbf3a478718c7b/src/rlinalg.jl#L148-L178">source</a></section><h2><a class="nav-anchor" id="Extremal-eigenvalue-estimates-1" href="#Extremal-eigenvalue-estimates-1">Extremal eigenvalue estimates</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="RandomizedLinAlg.reigmin" href="#RandomizedLinAlg.reigmin"><code>RandomizedLinAlg.reigmin</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">reigmin(A, iters=1)</code></pre><p>Estimate minimal eigenvalue randomly.</p><p><strong>Arguments</strong></p><ul><li><code>A</code>: Matrix whose maximal eigenvalue to estimate.</li></ul><p>Must be square and support premultiply (<code>A*⋅</code>).</p><ul><li><code>iters::Int=1</code>: Number of power iterations to run. (Recommended: <code>iters</code> ≤ 3)</li></ul><p><strong>Keywords</strong></p><ul><li><code>p::Real=0.05</code>: Probability that estimate fails to hold as an upper bound.</li></ul><p><strong>Output</strong></p><p>Interval <code>(x, y)</code> which contains the maximal eigenvalue of <code>A</code> with probability <code>1 - p</code>.</p><p><strong>References</strong></p><p>Corollary of Theorem 1 in <a href="#footnote-Dixon1983">[Dixon1983]</a></p></div></div><a class="source-link" target="_blank" href="https://github.com/haampie/RandomizedLinAlg.jl/blob/491c91d7b5a15a7addf8f47afacbf3a478718c7b/src/rlinalg.jl#L233-L256">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="RandomizedLinAlg.reigmax" href="#RandomizedLinAlg.reigmax"><code>RandomizedLinAlg.reigmax</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">reigmax(A, iters=1)</code></pre><p>Estimate maximal eigenvalue randomly.</p><p><strong>Arguments</strong></p><ul><li><code>A</code>: Matrix whose maximal eigenvalue to estimate.</li></ul><p>Must be square and support premultiply (<code>A*⋅</code>).</p><ul><li><code>iters::Int=1</code>: Number of power iterations to run. (Recommended: <code>iters</code> ≤ 3)</li></ul><p><strong>Keywords</strong></p><ul><li><code>p::Real=0.05</code>: Probability that estimate fails to hold as an upper bound.</li></ul><p><strong>Output</strong></p><p>Interval <code>(x, y)</code> which contains the maximal eigenvalue of <code>A</code> with probability <code>1 - p</code>.</p><p><strong>References</strong></p><p>Corollary of Theorem 1 in <a href="#footnote-Dixon1983">[Dixon1983]</a></p></div></div><a class="source-link" target="_blank" href="https://github.com/haampie/RandomizedLinAlg.jl/blob/491c91d7b5a15a7addf8f47afacbf3a478718c7b/src/rlinalg.jl#L196-L219">source</a></section><h2><a class="nav-anchor" id="Norm-estimate-1" href="#Norm-estimate-1">Norm estimate</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="RandomizedLinAlg.rnorm" href="#RandomizedLinAlg.rnorm"><code>RandomizedLinAlg.rnorm</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">rnorm(A, mvps)</code></pre><p>Compute a probabilistic upper bound on the norm of a matrix <code>A</code>. <code>‖A‖ ≤ α √(2/π) maxᵢ ‖Aωᵢ‖</code> with probability <code>p=α^(-mvps)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>A</code>: matrix whose norm to estimate.</li><li><code>mvps::Int</code>: number of matrix-vector products to compute.</li></ul><p><strong>Keywords</strong></p><ul><li><code>p::Real=0.05</code>: probability of upper bound failing.</li></ul><p><strong>Output</strong></p><p>Estimate of ‖A‖.</p><p>See also <a href="index.html#RandomizedLinAlg.rnorms"><code>rnorms</code></a> for a different estimator that uses  premultiplying by both <code>A</code> and <code>A&#39;</code>.</p><p><strong>References</strong></p><p>Lemma 4.1 of Halko2011</p></div></div><a class="source-link" target="_blank" href="https://github.com/haampie/RandomizedLinAlg.jl/blob/491c91d7b5a15a7addf8f47afacbf3a478718c7b/src/rlinalg.jl#L61-L86">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="RandomizedLinAlg.rnorms" href="#RandomizedLinAlg.rnorms"><code>RandomizedLinAlg.rnorms</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">rnorms(A, iters=1)</code></pre><p>Estimate matrix norm randomly using <code>A&#39;A</code>.</p><p>Compute a probabilistic upper bound on the norm of a matrix <code>A</code>.</p><pre><code class="language-none">ρ = √(‖(A&#39;A)ʲω‖/‖(A&#39;A)ʲ⁻¹ω‖)</code></pre><p>which is an estimate of the spectral norm of <code>A</code> produced by <code>iters</code> steps of the power method starting with normalized <code>ω</code>, is a lower bound on the true norm by a factor</p><pre><code class="language-none">ρ ≤ α ‖A‖</code></pre><p>with probability greater than <code>1 - p</code>, where <code>p = 4\sqrt(n/(iters-1)) α^(-2iters)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>A</code>: matrix whose norm to estimate.</li><li><code>iters::Int = 1</code>: mumber of power iterations to perform.</li></ul><p><strong>Keywords</strong></p><ul><li><code>p::Real = 0.05</code>: probability of upper bound failing.</li><li><code>At = A&#39;</code>: Transpose of <code>A</code>.</li></ul><p><strong>Output</strong></p><p>Estimate of ‖A‖.</p><p>See also <a href="index.html#RandomizedLinAlg.rnorm"><code>rnorm</code></a> for a different estimator that does not require premultiplying by <code>A&#39;</code></p><p><strong>References</strong></p><p>Appendix of <a href="#footnote-Liberty2007">[Liberty2007]</a>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/haampie/RandomizedLinAlg.jl/blob/491c91d7b5a15a7addf8f47afacbf3a478718c7b/src/rlinalg.jl#L97-L134">source</a></section><h2><a class="nav-anchor" id="Interpolative-Decomposition-1" href="#Interpolative-Decomposition-1">Interpolative Decomposition</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="RandomizedLinAlg.id" href="#RandomizedLinAlg.id"><code>RandomizedLinAlg.id</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">id(A, k, l)</code></pre><p>Compute and return the interpolative decomposition of <code>A</code>: A ≈ B * P</p><p>Where:</p><ul><li><code>B</code>&#39;s columns are a subset of the columns of <code>A</code></li><li>some subset of <code>P</code>&#39;s columns are the <code>k x k</code> identity, no entry of <code>P</code> exceeds magnitude 2, and</li><li>||B * P - A|| ≲ σ(A, k+1), the (<code>k+1</code>)st singular value of <code>A</code>.</li></ul><p><strong>Arguments</strong></p><p><code>A</code>: Matrix to factorize</p><p><code>k::Int</code>: Number of columns of A to return in B</p><p><code>l::Int</code>: Length of random vectors to project onto</p><p><strong>Output</strong></p><p><code>(::Interpolative)</code>: interpolative decomposition.</p><p><strong>Implementation note</strong></p><p>This is a hacky version of the algorithms described in \cite{Liberty2007} and \cite{Cheng2005}. The former refers to the factorization (3.1) of the latter.  However, it is not actually necessary to compute this factorization in its entirely to compute an interpolative decomposition.</p><p>Instead, it suffices to find some permutation of the first k columns of Y = R * A, extract the subset of A into B, then compute the P matrix as B\A which will automatically compute P using a suitable least-squares algorithm.</p><p>The approximation we use here is to compute the column pivots of Y, rather then use the true column pivots as would be computed by a column- pivoted QR process.</p><p><strong>References</strong></p><p>\cite[Algorithm I]{Liberty2007}</p><pre><code class="language-bibtex">@article{Cheng2005,
    author = {Cheng, H and Gimbutas, Z and Martinsson, P G and Rokhlin, V},
    doi = {10.1137/030602678},
    issn = {1064-8275},
    journal = {SIAM Journal on Scientific Computing},
    month = jan,
    number = {4},
    pages = {1389--1404},
    title = {On the Compression of Low Rank Matrices},
    volume = {26},
    year = {2005}
}</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/haampie/RandomizedLinAlg.jl/blob/491c91d7b5a15a7addf8f47afacbf3a478718c7b/src/factorization.jl#L22-L78">source</a></section><div class="footnote" id="footnote-Halko2011"><a href="#footnote-Halko2011"><strong>[Halko2011]</strong></a><p>Halko, Nathan, Per-Gunnar Martinsson, and Joel A. Tropp. &quot;Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions.&quot; SIAM review 53.2 (2011): 217-288.</p></div><div class="footnote" id="footnote-Dixon1983"><a href="#footnote-Dixon1983"><strong>[Dixon1983]</strong></a><p>Dixon, John D. &quot;Estimating extremal eigenvalues and condition numbers of matrices.&quot; SIAM Journal on Numerical Analysis 20.4 (1983): 812-814.</p></div><div class="footnote" id="footnote-Liberty2007"><a href="#footnote-Liberty2007"><strong>[Liberty2007]</strong></a><p>Liberty, Edo, et al. &quot;Randomized algorithms for the low-rank approximation of matrices.&quot; Proceedings of the National Academy of Sciences 104.51 (2007): 20167-20172.</p></div><footer><hr/></footer></article></body></html>
